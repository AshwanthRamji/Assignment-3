{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face generation\n",
    "In this project, you'll use generative adversarial networks to generate new images of faces.\n",
    "\n",
    "#Get the Data\n",
    "You'll be using two datasets in this project:\n",
    "\n",
    "MNIST\n",
    "CelebA\n",
    "Since the celebA dataset is complex and you're doing GANs in a project for the first time, we want you to test your neural network on MNIST before CelebA. Running the GANs on MNIST will allow you to see how well your model trains sooner.\n",
    "\n",
    "If you're using FloydHub, set data_dir to \"/input\" and use the FloydHub data ID \"R5KrjnANiKVhLWAkpXhNBe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import normal_latent_sampling, AdversarialOptimizerSimultaneous\n",
    "from keras_adversarial.legacy import l1l2, Dense, fit\n",
    "import keras.backend as K\n",
    "from mnist_utils import mnist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "Implement generator to generate an image using z. This function should be able to reuse the variables in the neural network. Use tf.variable_scope with a scope name of \"generator\" to allow the variables to be reused. The function should return the generated 28 x 28 x out_channel_dim images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(latent_dim, input_shape, hidden_dim=1024, reg=lambda: l1l2(1e-5, 1e-5)):\n",
    "    return Sequential([\n",
    "        Dense(int(hidden_dim / 4), name=\"generator_h1\", input_dim=latent_dim, W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 2), name=\"generator_h2\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(hidden_dim, name=\"generator_h3\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(np.prod(input_shape), name=\"generator_x_flat\", W_regularizer=reg()),\n",
    "        Activation('sigmoid'),\n",
    "        Reshape(input_shape, name=\"generator_x\")],\n",
    "        name=\"generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "Implement discriminator to create a discriminator neural network that discriminates on images. This function should be able to reuse the variables in the neural network. Use tf.variable_scope with a scope name of \"discriminator\" to allow the variables to be reused. The function should return a tuple of (tensor output of the discriminator, tensor logits of the discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(input_shape, hidden_dim=1024, reg=lambda: l1l2(1e-5, 1e-5), output_activation=\"sigmoid\"):\n",
    "    return Sequential([\n",
    "        Flatten(name=\"discriminator_flatten\", input_shape=input_shape),\n",
    "        Dense(hidden_dim, name=\"discriminator_h1\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 2), name=\"discriminator_h2\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(int(hidden_dim / 4), name=\"discriminator_h3\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(1, name=\"discriminator_y\", W_regularizer=reg()),\n",
    "        Activation(output_activation)],\n",
    "        name=\"discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gan Training\n",
    "Show Output\n",
    "Use this function to show the current output of the generator during training. It will help you determine how well the GANs is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator, discriminator, latent_dim,\n",
    "                targets=gan_targets, loss='binary_crossentropy'):\n",
    "    csvpath = os.path.join(path, \"history.csv\")\n",
    "    if os.path.exists(csvpath):\n",
    "        print(\"Already exists: {}\".format(csvpath))\n",
    "        return\n",
    "\n",
    "    print(\"Training: {}\".format(csvpath))\n",
    "    # gan (x - > yfake, yreal), z generated on GPU\n",
    "    gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\n",
    "\n",
    "    # print summary of models\n",
    "    generator.summary()\n",
    "    discriminator.summary()\n",
    "    gan.summary()\n",
    "\n",
    "    # build adversarial model\n",
    "    model = AdversarialModel(base_model=gan,\n",
    "                             player_params=[generator.trainable_weights, discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers=[opt_g, opt_d],\n",
    "                              loss=loss)\n",
    "\n",
    "    # create callback to generate images\n",
    "    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "\n",
    "    def generator_sampler():\n",
    "        return generator.predict(zsamples).reshape((10, 10, 28, 28))\n",
    "\n",
    "    generator_cb = ImageGridCallback(os.path.join(path, \"epoch-{:03d}.png\"), generator_sampler)\n",
    "\n",
    "    # train model\n",
    "    xtrain, xtest = mnist_data()\n",
    "    y = targets(xtrain.shape[0])\n",
    "    ytest = targets(xtest.shape[0])\n",
    "    callbacks = [generator_cb]\n",
    "    if K.backend() == \"tensorflow\":\n",
    "        callbacks.append(\n",
    "            TensorBoard(log_dir=os.path.join(path, 'logs'), histogram_freq=0, write_graph=True, write_images=True))\n",
    "    history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=callbacks, nb_epoch=nb_epoch,batch_size=32)\n",
    "\n",
    "    # save history to CSV\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(csvpath)\n",
    "\n",
    "    # save models\n",
    "    generator.save(os.path.join(path, \"generator.h5\"))\n",
    "    discriminator.save(os.path.join(path, \"discriminator.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: output/gan/history.csv\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_h1 (Dense)         (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "generator_h2 (Dense)         (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "generator_h3 (Dense)         (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "generator_x_flat (Dense)     (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "generator_x (Reshape)        (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_flatten (Flatt (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h1 (Dense)     (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "discriminator_h2 (Dense)     (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h3 (Dense)     (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_y (Dense)      (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "discriminator_flatten_input (In (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 100)          0           discriminator_flatten_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "gan (Model)                     [(None, 1), (None, 1 2946577     lambda_2[0][0]                   \n",
      "                                                                 discriminator_flatten_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "yfake (Activation)              (None, 1)            0           gan[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "yreal (Activation)              (None, 1)            0           gan[1][1]                        \n",
      "==================================================================================================\n",
      "Total params: 2,946,577\n",
      "Trainable params: 2,946,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 38s 638us/step - loss: 23.8072 - generator_loss: 20.3301 - generator_yfake_loss: 7.8747 - generator_yreal_loss: 9.0464 - discriminator_loss: 3.4771 - discriminator_yfake_loss: 0.0245 - discriminator_yreal_loss: 0.0436 - val_loss: 20.3881 - val_generator_loss: 17.5844 - val_generator_yfake_loss: 3.4141 - val_generator_yreal_loss: 11.4195 - val_discriminator_loss: 2.8038 - val_discriminator_yfake_loss: 0.0443 - val_discriminator_yreal_loss: 0.0088\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 46s 760us/step - loss: 23.9620 - generator_loss: 21.2819 - generator_yfake_loss: 6.7791 - generator_yreal_loss: 11.8545 - discriminator_loss: 2.6801 - discriminator_yfake_loss: 0.0129 - discriminator_yreal_loss: 0.0189 - val_loss: 27.4988 - val_generator_loss: 24.9474 - val_generator_yfake_loss: 10.3182 - val_generator_yreal_loss: 12.1076 - val_discriminator_loss: 2.5514 - val_discriminator_yfake_loss: 1.1493e-04 - val_discriminator_yreal_loss: 0.0297\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 49s 817us/step - loss: 24.0585 - generator_loss: 21.5367 - generator_yfake_loss: 6.8413 - generator_yreal_loss: 12.2202 - discriminator_loss: 2.5218 - discriminator_yfake_loss: 0.0179 - discriminator_yreal_loss: 0.0287 - val_loss: 20.9707 - val_generator_loss: 18.4520 - val_generator_yfake_loss: 5.4604 - val_generator_yreal_loss: 10.5094 - val_discriminator_loss: 2.5188 - val_discriminator_yfake_loss: 0.0195 - val_discriminator_yreal_loss: 0.0170\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 47s 786us/step - loss: 20.5590 - generator_loss: 17.8919 - generator_yfake_loss: 5.1697 - generator_yreal_loss: 10.1638 - discriminator_loss: 2.6671 - discriminator_yfake_loss: 0.0405 - discriminator_yreal_loss: 0.0681 - val_loss: 19.4298 - val_generator_loss: 16.7451 - val_generator_yfake_loss: 4.0798 - val_generator_yreal_loss: 10.1260 - val_discriminator_loss: 2.6848 - val_discriminator_yfake_loss: 0.0576 - val_discriminator_yreal_loss: 0.0879\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 45s 758us/step - loss: 20.2862 - generator_loss: 17.6649 - generator_yfake_loss: 4.7972 - generator_yreal_loss: 10.3710 - discriminator_loss: 2.6213 - discriminator_yfake_loss: 0.0476 - discriminator_yreal_loss: 0.0769 - val_loss: 21.3303 - val_generator_loss: 18.7621 - val_generator_yfake_loss: 6.0814 - val_generator_yreal_loss: 10.2108 - val_discriminator_loss: 2.5682 - val_discriminator_yfake_loss: 0.0053 - val_discriminator_yreal_loss: 0.0930\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 44s 727us/step - loss: 20.7298 - generator_loss: 18.2328 - generator_yfake_loss: 4.8443 - generator_yreal_loss: 11.0072 - discriminator_loss: 2.4970 - discriminator_yfake_loss: 0.0441 - discriminator_yreal_loss: 0.0717 - val_loss: 20.5209 - val_generator_loss: 18.0555 - val_generator_yfake_loss: 5.3835 - val_generator_yreal_loss: 10.3232 - val_discriminator_loss: 2.4654 - val_discriminator_yfake_loss: 0.0206 - val_discriminator_yreal_loss: 0.0959\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 20.1159 - generator_loss: 17.6788 - generator_yfake_loss: 4.8837 - generator_yreal_loss: 10.4866 - discriminator_loss: 2.4371 - discriminator_yfake_loss: 0.0493 - discriminator_yreal_loss: 0.0794 - val_loss: 18.4823 - val_generator_loss: 16.0895 - val_generator_yfake_loss: 4.7041 - val_generator_yreal_loss: 9.1083 - val_discriminator_loss: 2.3929 - val_discriminator_yfake_loss: 0.0291 - val_discriminator_yreal_loss: 0.0866\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 44s 725us/step - loss: 18.6321 - generator_loss: 16.2253 - generator_yfake_loss: 4.5207 - generator_yreal_loss: 9.4466 - discriminator_loss: 2.4069 - discriminator_yfake_loss: 0.0603 - discriminator_yreal_loss: 0.0887 - val_loss: 18.6170 - val_generator_loss: 16.2088 - val_generator_yfake_loss: 4.8694 - val_generator_yreal_loss: 9.1062 - val_discriminator_loss: 2.4082 - val_discriminator_yfake_loss: 0.0369 - val_discriminator_yreal_loss: 0.1381\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 42s 697us/step - loss: 18.2291 - generator_loss: 15.8326 - generator_yfake_loss: 4.4648 - generator_yreal_loss: 9.1329 - discriminator_loss: 2.3965 - discriminator_yfake_loss: 0.0651 - discriminator_yreal_loss: 0.0966 - val_loss: 19.0572 - val_generator_loss: 16.6348 - val_generator_yfake_loss: 5.4480 - val_generator_yreal_loss: 8.9717 - val_discriminator_loss: 2.4224 - val_discriminator_yfake_loss: 0.0221 - val_discriminator_yreal_loss: 0.1853\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 18.3474 - generator_loss: 15.9743 - generator_yfake_loss: 4.3866 - generator_yreal_loss: 9.3840 - discriminator_loss: 2.3731 - discriminator_yfake_loss: 0.0677 - discriminator_yreal_loss: 0.1018 - val_loss: 18.1635 - val_generator_loss: 15.8610 - val_generator_yfake_loss: 4.7468 - val_generator_yreal_loss: 8.9254 - val_discriminator_loss: 2.3026 - val_discriminator_yfake_loss: 0.0285 - val_discriminator_yreal_loss: 0.0852\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 40s 666us/step - loss: 17.5931 - generator_loss: 15.2207 - generator_yfake_loss: 4.2693 - generator_yreal_loss: 8.7619 - discriminator_loss: 2.3724 - discriminator_yfake_loss: 0.0746 - discriminator_yreal_loss: 0.1082 - val_loss: 17.8221 - val_generator_loss: 15.5326 - val_generator_yfake_loss: 4.5584 - val_generator_yreal_loss: 8.7974 - val_discriminator_loss: 2.2895 - val_discriminator_yfake_loss: 0.0381 - val_discriminator_yreal_loss: 0.0746\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 38s 640us/step - loss: 17.4199 - generator_loss: 15.0819 - generator_yfake_loss: 4.1243 - generator_yreal_loss: 8.8045 - discriminator_loss: 2.3379 - discriminator_yfake_loss: 0.0752 - discriminator_yreal_loss: 0.1096 - val_loss: 18.8089 - val_generator_loss: 16.5371 - val_generator_yfake_loss: 4.3043 - val_generator_yreal_loss: 10.0891 - val_discriminator_loss: 2.2718 - val_discriminator_yfake_loss: 0.0519 - val_discriminator_yreal_loss: 0.0761\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 40s 660us/step - loss: 17.6195 - generator_loss: 15.2690 - generator_yfake_loss: 4.1600 - generator_yreal_loss: 8.9578 - discriminator_loss: 2.3505 - discriminator_yfake_loss: 0.0816 - discriminator_yreal_loss: 0.1178 - val_loss: 16.6496 - val_generator_loss: 14.2792 - val_generator_yfake_loss: 3.1443 - val_generator_yreal_loss: 8.9810 - val_discriminator_loss: 2.3704 - val_discriminator_yfake_loss: 0.1649 - val_discriminator_yreal_loss: 0.0516\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 35s 586us/step - loss: 16.6380 - generator_loss: 14.2883 - generator_yfake_loss: 4.0308 - generator_yreal_loss: 8.1182 - discriminator_loss: 2.3496 - discriminator_yfake_loss: 0.0870 - discriminator_yreal_loss: 0.1233 - val_loss: 15.9397 - val_generator_loss: 13.6009 - val_generator_yfake_loss: 4.2846 - val_generator_yreal_loss: 7.1779 - val_discriminator_loss: 2.3388 - val_discriminator_yfake_loss: 0.0562 - val_discriminator_yreal_loss: 0.1443\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 16.4842 - generator_loss: 14.1134 - generator_yfake_loss: 3.9358 - generator_yreal_loss: 8.0369 - discriminator_loss: 2.3708 - discriminator_yfake_loss: 0.0953 - discriminator_yreal_loss: 0.1349 - val_loss: 16.1315 - val_generator_loss: 13.7487 - val_generator_yfake_loss: 3.3398 - val_generator_yreal_loss: 8.2769 - val_discriminator_loss: 2.3828 - val_discriminator_yfake_loss: 0.1358 - val_discriminator_yreal_loss: 0.1149\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # z \\in R^100\n",
    "    latent_dim = 100\n",
    "    # x \\in R^{28x28}\n",
    "    input_shape=(28, 28)\n",
    "    # generator (z -> x)\n",
    "    generator = model_generator(latent_dim, input_shape)\n",
    "    # discriminator (x -> y)\n",
    "    discriminator = model_discriminator(input_shape)\n",
    "    example_gan(AdversarialOptimizerSimultaneous(), \"output/gan/\",\n",
    "                opt_g=Adam(1e-4, decay=1e-4),\n",
    "                opt_d=Adam(1e-3, decay=1e-4),\n",
    "                nb_epoch=15, generator=generator, discriminator=discriminator,latent_dim=latent_dim)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
